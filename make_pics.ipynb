{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动出图\n",
    "\n",
    "流程：\n",
    "- 让ai帮我们生成prompt，然后保存到某个txt文件里\n",
    "- 以这个txt文件为输入，调用已经写好的ComfyUI脚本，生成图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in e:\\autogen-test\\.venv\\lib\\site-packages (0.1.11)\n",
      "Requirement already satisfied: diskcache in e:\\autogen-test\\.venv\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: flaml in e:\\autogen-test\\.venv\\lib\\site-packages (from pyautogen) (2.1.1)\n",
      "Requirement already satisfied: openai in e:\\autogen-test\\.venv\\lib\\site-packages (from pyautogen) (0.28.1)\n",
      "Requirement already satisfied: python-dotenv in e:\\autogen-test\\.venv\\lib\\site-packages (from pyautogen) (1.0.0)\n",
      "Requirement already satisfied: termcolor in e:\\autogen-test\\.venv\\lib\\site-packages (from pyautogen) (2.3.0)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in e:\\autogen-test\\.venv\\lib\\site-packages (from flaml->pyautogen) (1.26.1)\n",
      "Requirement already satisfied: requests>=2.20 in e:\\autogen-test\\.venv\\lib\\site-packages (from openai->pyautogen) (2.31.0)\n",
      "Requirement already satisfied: tqdm in e:\\autogen-test\\.venv\\lib\\site-packages (from openai->pyautogen) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in e:\\autogen-test\\.venv\\lib\\site-packages (from openai->pyautogen) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\autogen-test\\.venv\\lib\\site-packages (from requests>=2.20->openai->pyautogen) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\autogen-test\\.venv\\lib\\site-packages (from requests>=2.20->openai->pyautogen) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\autogen-test\\.venv\\lib\\site-packages (from requests>=2.20->openai->pyautogen) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\autogen-test\\.venv\\lib\\site-packages (from requests>=2.20->openai->pyautogen) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\autogen-test\\.venv\\lib\\site-packages (from aiohttp->openai->pyautogen) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\autogen-test\\.venv\\lib\\site-packages (from aiohttp->openai->pyautogen) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\autogen-test\\.venv\\lib\\site-packages (from aiohttp->openai->pyautogen) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\autogen-test\\.venv\\lib\\site-packages (from aiohttp->openai->pyautogen) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\autogen-test\\.venv\\lib\\site-packages (from aiohttp->openai->pyautogen) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\autogen-test\\.venv\\lib\\site-packages (from aiohttp->openai->pyautogen) (1.3.1)\n",
      "Requirement already satisfied: colorama in e:\\autogen-test\\.venv\\lib\\site-packages (from tqdm->openai->pyautogen) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# 先得安装pyautogen\n",
    "%pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置Api入口\n",
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建完成这个项目需要的agent\n",
    "llm_config = {\n",
    "    \"config_list\": config_list, \n",
    "    \"seed\": 42,\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\":\"savePrompts\",\n",
    "            \"description\":\"save prompts to a text file\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompts\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"the prompts to be saved\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"message\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    }\n",
    "\n",
    "# 首先，我们需要一个与人类用户交互的proxy agent\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"User_proxy\", # 这里的命令规则是只能包含字母(大写和小写)、数字、下划线和连字符，长度在1到64个字符之间。\n",
    "   system_message=\"A human admin.\",\n",
    "   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"output\"},\n",
    "   human_input_mode=\"NEVER\",\n",
    "   llm_config=llm_config,\n",
    ")\n",
    "# 接下来，我们需要一个把用于中英文翻译的agent\n",
    "translator = autogen.AssistantAgent(\n",
    "    name=\"Translator\",\n",
    "    system_message=\"Your task is to translate the user's Chinese into English and do nothing else.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "# 然后，我们需要一个把按用户需求生成绘图prompt的agent\n",
    "prompts_generator = autogen.AssistantAgent(\n",
    "    name=\"Prompts_generator\",\n",
    "    system_message=\"\"\"\n",
    "    Your task is to generate some prompts for ai-generated picture. And don't do anything else.\n",
    "    \n",
    "    These prompts must meet the following requirements:\n",
    "    - Include description of attire, background, lighting and shadow.\n",
    "    - Each sentence should be limited to 50 words.\n",
    "    \n",
    "    for example:\n",
    "        'Wearing a futuristic suit, she stands in front of an abstract mural, neon lights casting bold shadows across her metallic armor, mirroring the vibrant colors of the artwork.'\n",
    "    \"\"\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "# 我们还需要一个能把prompt文件保存为text的agent\n",
    "prompts_saver = autogen.UserProxyAgent(\n",
    "    name=\"Prompts_saver\", \n",
    "    system_message=\"A proxy agent that saves prompts to a text file.\",\n",
    "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"output\"},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "def savePrompts(prompts):\n",
    "    print(\"got message: \", prompts)\n",
    "    save_file_path = \"output\\generated_text.txt\"\n",
    "    try:\n",
    "        with open(save_file_path, \"a\") as f:\n",
    "            f.write(prompts + \"\\n\")\n",
    "        return f\"image prompt file generated ,and saved at {save_file_path}. TERMINATE\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"image prompt file generated failed, error: {e}. TERMINATE\"\n",
    "\n",
    "prompts_saver.register_function(\n",
    "    function_map={\n",
    "        \"savePrompts\": savePrompts,\n",
    "    }\n",
    ")\n",
    "\n",
    "# 然后，我们建一个群把它们放在一起\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, translator, prompts_generator, prompts_saver], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户输入需求\n",
    "user_input = \"帮我生成一些女网红的写真照片的提示词，然后保存成文件。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "帮我生成一些女网红的写真照片的提示词，然后保存成文件。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTranslator\u001b[0m (to chat_manager):\n",
      "\n",
      "Help me generate some photo shoot prompt words for female internet celebrities, then save them as a file.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPrompts_generator\u001b[0m (to chat_manager):\n",
      "\n",
      "1. 'Dressed in soft, bohemian style clothing, she is lounging in the warm golden glow of a cozy café, her long, flowing skirts creating fluid shadows on the worn wooden tables.'\n",
      "2. 'In a chic, modern apartment, lit by the serene light of dawn, she wears a silk bathrobe. Her delicately curled hair casting a soft shadow on the elegant marble floor.'\n",
      "3. 'Adorned in vibrant workout gear, she is caught midjog in a lush forest, dawn's first rays providing dramatic illumination and casting long, active shadows.'\n",
      "4. 'Outside a rustic cottage, under the warm evening light, she stands wearing a vintage dress, the setting sun casting romantic shadows over the fence and blossoms.'\n",
      "5. 'In a downtown rooftop, she is dancing in a trendy party outfit with the city lights in the background, their blinking illumination casting dynamic shadows on her moving silhouette.'\n",
      "6. 'Caught mid laugh in her luminous kitchen, she is casually yet stylishly dressed. Morning sunlight streams through the window creating playful shadows around her.'\n",
      "7. 'Boldly posed against a graffitied wall in a hip urban environment, she wears a rebellious ensemble of leather, the shadows cast by overhead streetlights creating an aura of edginess.'\n",
      "8. 'In a serene, snow-clad village, she is rosy-cheeked and bundled into an oversized knit sweater and boots. The cool winter sunlight creates high contrast between light and shadow.'\n",
      "\u001b[32m***** Suggested function Call: savePrompts *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"prompts\": \"1. 'Dressed in soft, bohemian style clothing, she is lounging in the warm golden glow of a cozy café, her long, flowing skirts creating fluid shadows on the worn wooden tables.'\\n2. 'In a chic, modern apartment, lit by the serene light of dawn, she wears a silk bathrobe. Her delicately curled hair casting a soft shadow on the elegant marble floor.'\\n3. 'Adorned in vibrant workout gear, she is caught midjog in a lush forest, dawn's first rays providing dramatic illumination and casting long, active shadows.'\\n4. 'Outside a rustic cottage, under the warm evening light, she stands wearing a vintage dress, the setting sun casting romantic shadows over the fence and blossoms.'\\n5. 'In a downtown rooftop, she is dancing in a trendy party outfit with the city lights in the background, their blinking illumination casting dynamic shadows on her moving silhouette.'\\n6. 'Caught mid laugh in her luminous kitchen, she is casually yet stylishly dressed. Morning sunlight streams through the window creating playful shadows around her.'\\n7. 'Boldly posed against a graffitied wall in a hip urban environment, she wears a rebellious ensemble of leather, the shadows cast by overhead streetlights creating an aura of edginess.'\\n8. 'In a serene, snow-clad village, she is rosy-cheeked and bundled into an oversized knit sweater and boots. The cool winter sunlight creates high contrast between light and shadow.'\"\n",
      "}\n",
      "\u001b[32m************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION savePrompts...\u001b[0m\n",
      "got message:  1. 'Dressed in soft, bohemian style clothing, she is lounging in the warm golden glow of a cozy café, her long, flowing skirts creating fluid shadows on the worn wooden tables.'\n",
      "2. 'In a chic, modern apartment, lit by the serene light of dawn, she wears a silk bathrobe. Her delicately curled hair casting a soft shadow on the elegant marble floor.'\n",
      "3. 'Adorned in vibrant workout gear, she is caught midjog in a lush forest, dawn's first rays providing dramatic illumination and casting long, active shadows.'\n",
      "4. 'Outside a rustic cottage, under the warm evening light, she stands wearing a vintage dress, the setting sun casting romantic shadows over the fence and blossoms.'\n",
      "5. 'In a downtown rooftop, she is dancing in a trendy party outfit with the city lights in the background, their blinking illumination casting dynamic shadows on her moving silhouette.'\n",
      "6. 'Caught mid laugh in her luminous kitchen, she is casually yet stylishly dressed. Morning sunlight streams through the window creating playful shadows around her.'\n",
      "7. 'Boldly posed against a graffitied wall in a hip urban environment, she wears a rebellious ensemble of leather, the shadows cast by overhead streetlights creating an aura of edginess.'\n",
      "8. 'In a serene, snow-clad village, she is rosy-cheeked and bundled into an oversized knit sweater and boots. The cool winter sunlight creates high contrast between light and shadow.'\n",
      "\u001b[33mPrompts_saver\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"savePrompts\" *****\u001b[0m\n",
      "image prompt file generated ,and saved at output\\generated_text.txt\n",
      "\u001b[32m********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "我已经为你生成了一些適合女性网络红人拍照的提示词，并已经保存到文件中。文件名为 \"generated_text.txt\"。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTranslator\u001b[0m (to chat_manager):\n",
      "\n",
      "I have generated some photo shoot prompts suitable for female internet celebrities for you, and they are saved in a file. The file name is \"generated_text.txt\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Exactly. If you have any other requests or need further assistance, please let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "确切说，如果你有其他需求或需要进一步的帮助，请让我知道！\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTranslator\u001b[0m (to chat_manager):\n",
      "\n",
      "Exactly. If you have any other requests or need further assistance, please let me know!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "I'm glad to hear that you're satisfied! If you have any more prompts or tasks, don't hesitate to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "我很高兴你满意这个结果！如果你有更多的提示或任务，不要犹豫，尽管提问。\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTranslator\u001b[0m (to chat_manager):\n",
      "\n",
      "I'm glad to hear that you're satisfied! If you have any more prompts or tasks, don't hesitate to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 执行代码\n",
    "user_proxy.initiate_chat(manager,message=user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
